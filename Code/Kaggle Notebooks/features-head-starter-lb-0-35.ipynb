{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006778,"end_time":"2024-02-07T17:23:10.119762","exception":false,"start_time":"2024-02-07T17:23:10.112984","status":"completed"},"tags":[]},"source":["# Features+Head Ensemble Starter for HMS Brain Comp\n","This is Features+Head is a combination and ensemble Starter notebook for Kaggle's HMS brain comp. We can train 4 different models using:\n","- Kaggle's spectrograms (CV 0.6365 - LB 0.43)\n","- Chris's EEG spectrograms(modified version) (CV 0.6336 - LB 0.41)\n","- Both Kaggle and EEG spectrograms (CV 0.5726 - LB 0.39)\n","- Chris's [WaveNet][4] (CV 0.6992 - LB 0.41)\n","\n","**The Ensemble achieves LB 0.35** \n","Great discussion [here][5] by @KOLOO that led to the latest score!\n","\n","Features+Head Starter uses Chris Deotte's Kaggle dataset [here][1]. Also Uses Chris's EEG spectrograms [here][3] (modified version) \n","\n","### Train and Infer Tips\n","\n","This notebook can be used both to train and submit (infer) to Kaggle LB. When training, you can set variable `submission = False` , you can also set `TEST_MODE = TRUE` to upload 500 samples queckly instead of the whole dataset for testing. \n","\n","To train a specific model type, you should set `DATA_TYPE = 'both|eeg|kaggle|raw'`, `kaggle` to train on Kaggle's spectrograms, `eeg` to train on EEG's spectrograms, `both` to train on Kaggle's and EEG's spectrograms, `raw` to train on EEG's signal with WaveNet,\n","\n","For submission after training models, you should save them in the LOAD_MODELS_FROM dataset, then run this notebook with `submission = True`.\n","\n","Once we have all the models saved to LOAD_MODELS_FROM and ready ensemble, we should set `submission = True` and `ENSEMBLE = True` and set the models versions that we prior specified, as well as their `LBs` for weighted ensemble.\n","\n","This notebook is made as generic as possible to expand and try different experiments.\n","\n","What you could do:\n","- Change EfficientNetB(0-7) with `LOAD_BACKBONE_FROM`\n","- Data augmentation by setting DataGenerator's parameter to `augment = True`\n","- Different image configurations as input.\n","- WaveNet model tuning.\n","\n","\n","This notebook is a direct descendent of Chris's notebook [here][2]\n","\n","[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n","[2]: https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57\n","[3]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n","[4]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/468684\n","[5]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-27T04:56:11.483639Z","iopub.status.busy":"2024-02-27T04:56:11.482812Z","iopub.status.idle":"2024-02-27T04:56:24.339241Z","shell.execute_reply":"2024-02-27T04:56:24.338226Z","shell.execute_reply.started":"2024-02-27T04:56:11.483603Z"},"papermill":{"duration":13.702195,"end_time":"2024-02-07T17:23:23.827764","exception":false,"start_time":"2024-02-07T17:23:10.125569","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["Using 2 GPUs\n"]}],"source":["import os, random\n","import tensorflow as tf\n","import tensorflow\n","import tensorflow.keras.backend as K\n","import pandas as pd, numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","\n","LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n","LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models/'\n","VER = 37\n","DATA_TYPE = 'raw' # both|eeg|kaggle|raw\n","TEST_MODE = False\n","submission = True\n","\n","# Setup for ensemble\n","ENSEMBLE = True\n","LBs = [0.39,0.41,0.43,0.41] # for weighted ensemble we use LBs of each model\n","VERK = 33.2 # Kaggle's spectrogram model version\n","VERB = 35 # Kaggle's and EEG's spectrogram model version\n","VERE = 34 # EEG's spectrogram model version\n","VERR = 37 # EEG's raw wavenet model version, trained on single GPU\n","\n","np.random.seed(42)\n","random.seed(42)\n","tf.random.set_seed(42)\n","\n","# USE SINGLE GPU, MULTIPLE GPUS \n","gpus = tf.config.list_physical_devices('GPU')\n","# WE USE MIXED PRECISION\n","tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n","if len(gpus)>1:\n","    strategy = tf.distribute.MirroredStrategy()\n","    print(f'Using {len(gpus)} GPUs')\n","else:\n","    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n","    print(f'Using {len(gpus)} GPU')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005556,"end_time":"2024-02-07T17:23:23.84064","exception":false,"start_time":"2024-02-07T17:23:23.835084","status":"completed"},"tags":[]},"source":["# Load and create Non-Overlapping Eeg Id Train Data\n","The competition data description says that test data does not have multiple crops from the same `eeg_id`. Therefore we will train and validate using only 1 crop per `eeg_id`. There is a discussion about this [here][1].\n","[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-27T04:56:24.340794Z","iopub.status.busy":"2024-02-27T04:56:24.340302Z","iopub.status.idle":"2024-02-27T04:56:24.354394Z","shell.execute_reply":"2024-02-27T04:56:24.353369Z","shell.execute_reply.started":"2024-02-27T04:56:24.340769Z"},"papermill":{"duration":0.347751,"end_time":"2024-02-07T17:23:24.193927","exception":false,"start_time":"2024-02-07T17:23:23.846176","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n","\n","def eeg_from_parquet(parquet_path):\n","\n","    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n","    rows = len(eeg)\n","    offset = (rows-10_000)//2\n","    eeg = eeg.iloc[offset:offset+10_000]\n","    data = np.zeros((10_000,len(FEATS2)))\n","    for j,col in enumerate(FEATS2):\n","        \n","        # FILL NAN\n","        x = eeg[col].values.astype('float32')\n","        m = np.nanmean(x)\n","        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n","        else: x[:] = 0\n","        \n","        data[:,j] = x\n","\n","    return data\n","\n","def add_kl(data):\n","    import torch\n","    labels = data[TARGETS].values + 1e-5\n","\n","    # compute kl-loss with uniform distribution by pytorch\n","    data['kl'] = torch.nn.functional.kl_div(\n","        torch.log(torch.tensor(labels)),\n","        torch.tensor([1 / 6] * 6),\n","        reduction='none'\n","    ).sum(dim=1).numpy()\n","    return data0\n","\n","def reset_seed(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    tf.random.set_seed(seed)\n","    \n","if not submission:\n","    train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n","    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n","    train = train.groupby('eeg_id')[META+TARGETS\n","                           ].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n","    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n","    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n","    train = add_kl(train)\n","    print(train.head(1).to_string())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005271,"end_time":"2024-02-07T17:23:24.20513","exception":false,"start_time":"2024-02-07T17:23:24.199859","status":"completed"},"tags":[]},"source":["# Read Train Spectrograms and EEGs\n","\n","We can read 3 file from Chris's [Kaggle dataset here][1] which contains all the 11k spectrograms. From Chris's modified EEG spectrogram [here][2]. From Chris's EEG signals [here][3]\n","\n","[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n","[2]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n","[3]: https://www.kaggle.com/datasets/cdeotte/brain-eegs"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-27T04:56:24.356129Z","iopub.status.busy":"2024-02-27T04:56:24.355763Z","iopub.status.idle":"2024-02-27T04:56:24.384803Z","shell.execute_reply":"2024-02-27T04:56:24.383760Z","shell.execute_reply.started":"2024-02-27T04:56:24.356095Z"},"papermill":{"duration":222.18751,"end_time":"2024-02-07T17:27:06.399257","exception":false,"start_time":"2024-02-07T17:23:24.211747","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 0 ns, sys: 5 µs, total: 5 µs\n","Wall time: 10.3 µs\n"]}],"source":["%%time\n","if not submission:\n","    # FOR TESTING SET READ_FILES TO TRUE\n","    if TEST_MODE:\n","        train = train.sample(500,random_state=42).reset_index(drop=True)\n","        spectrograms = {}\n","        for i,e in enumerate(train.spec_id.values):\n","            if i%100==0: print(i,', ',end='')\n","            x = pd.read_parquet(f'/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/{e}.parquet')\n","            spectrograms[e] = x.values\n","        all_eegs = {}\n","        for i,e in enumerate(train.eeg_id.values):\n","            if i%100==0: print(i,', ',end='')\n","            x = np.load(f'/kaggle/input/eeg-spectrograms/EEG_Spectrograms/{e}.npy')\n","            all_eegs[e] = x\n","        all_raw_eegs = {}\n","        for i,e in enumerate(train.eeg_id.values):\n","            if i%100==0: print(i,', ',end='')\n","            x = eeg_from_parquet(f'/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/{e}.parquet')              \n","            all_raw_eegs[e] = x\n","    else:\n","        spectrograms = None\n","        all_eegs = None\n","        all_raw_eegs = None\n","        if DATA_TYPE=='both' or DATA_TYPE=='kaggle':\n","            spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n","        if DATA_TYPE=='both' or DATA_TYPE=='eeg':\n","            all_eegs = np.load('/kaggle/input/eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n","        if DATA_TYPE=='raw':\n","            all_raw_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00561,"end_time":"2024-02-07T17:27:06.410813","exception":false,"start_time":"2024-02-07T17:27:06.405203","status":"completed"},"tags":[]},"source":["# DATA GENERATOR\n","This data generator outputs 512x512x3, the spectrogram and eeg images are concatenated all togother in a single image. For using data augmention you can set `augment = True` when creating the train data generator."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:33.205066Z","iopub.status.busy":"2024-02-22T12:22:33.204198Z","iopub.status.idle":"2024-02-22T12:22:35.420589Z","shell.execute_reply":"2024-02-22T12:22:35.419443Z","shell.execute_reply.started":"2024-02-22T12:22:33.205007Z"},"papermill":{"duration":2.589361,"end_time":"2024-02-07T17:27:09.006112","exception":false,"start_time":"2024-02-07T17:27:06.416751","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import albumentations as albu\n","from scipy.signal import butter, lfilter\n","\n","class DataGenerator():\n","    'Generates data for Keras'\n","    def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None, augment=False, mode='train', data_type=DATA_TYPE): \n","        self.data = data\n","        self.augment = augment\n","        self.mode = mode\n","        self.data_type = data_type\n","        self.specs = specs\n","        self.eeg_specs = eeg_specs\n","        self.raw_eegs = raw_eegs\n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        X, y = self.data_generation(index)\n","        if self.augment: X = self.augmentation(X)\n","        return X, y\n","    \n","    def __call__(self):\n","        for i in range(self.__len__()):\n","            yield self.__getitem__(i)\n","            \n","            if i == self.__len__()-1:\n","                self.on_epoch_end()\n","                \n","    def on_epoch_end(self):\n","        if self.mode=='train': \n","            self.data = self.data.sample(frac=1).reset_index(drop=True)\n","    \n","    def data_generation(self, index):\n","        if self.data_type == 'both':\n","            X,y = self.generate_all_specs(index)\n","        elif self.data_type == 'eeg' or self.data_type == 'kaggle':\n","            X,y = self.generate_specs(index)\n","        elif self.data_type == 'raw':\n","            X,y = self.generate_raw(index)\n","\n","        return X,y\n","    \n","    def generate_all_specs(self, index):\n","        X = np.zeros((512,512,3),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        if self.mode=='test': \n","            offset = 0\n","        else:\n","            offset = int(row.offset/2)\n","            \n","        eeg = self.eeg_specs[row.eeg_id]\n","        spec = self.specs[row.spec_id]\n","        \n","        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in range(4)]\n","        img = np.stack(imgs,axis=-1)\n","        # LOG TRANSFORM SPECTROGRAM\n","        img = np.clip(img,np.exp(-4),np.exp(8))\n","        img = np.log(img)\n","            \n","        # STANDARDIZE PER IMAGE\n","        img = np.nan_to_num(img, nan=0.0)    \n","            \n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n","        X[100+56:200+56,:256,0] = img[:,22:-22,2] # LP_k\n","        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # RL_k\n","        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n","\n","        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n","        X[100+56:200+56,256:,0] = img[:,22:-22,1] # RL_k\n","        X[0_0+56:100+56,256:,1] = img[:,22:-22,2] # LP_k\n","        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n","        \n","        # EEG\n","        img = eeg\n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n","        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n","        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n","        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n","\n","        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n","        X[300+56:400+56,256:,0] = img[:,22:-22,1] # LP_e\n","        X[200+56:300+56,256:,1] = img[:,22:-22,2] # RL_e\n","        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n","        \n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","        \n","        return X,y\n","    \n","    def generate_specs(self, index):\n","        X = np.zeros((512,512,3),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        if self.mode=='test': \n","            offset = 0\n","        else:\n","            offset = int(row.offset/2)\n","            \n","        if self.data_type == 'eeg':\n","            img = self.eeg_specs[row.eeg_id]\n","        elif self.data_type == 'kaggle':\n","            spec = self.specs[row.spec_id]\n","            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in range(4)]\n","            img = np.stack(imgs,axis=-1)\n","            # LOG TRANSFORM SPECTROGRAM\n","            img = np.clip(img,np.exp(-4),np.exp(8))\n","            img = np.log(img)\n","            \n","            # STANDARDIZE PER IMAGE\n","            img = np.nan_to_num(img, nan=0.0)    \n","            \n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        \n","        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n","        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n","        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n","        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n","        \n","        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n","        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n","        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n","        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n","        \n","        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n","        X[300+56:400+56,:256,0] = img[:,22:-22,2]\n","        X[200+56:300+56,:256,1] = img[:,22:-22,1]\n","        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n","        \n","        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n","        X[300+56:400+56,256:,0] = img[:,22:-22,1]\n","        X[200+56:300+56,256:,1] = img[:,22:-22,2]\n","        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n","        \n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","        \n","        return X,y\n","    \n","    def generate_raw(self,index):\n","        X = np.zeros((10_000,8),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        eeg = self.raw_eegs[row.eeg_id]\n","            \n","        # FEATURE ENGINEER\n","        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n","        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n","            \n","        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n","        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n","            \n","        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n","        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n","            \n","        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n","        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n","            \n","        # STANDARDIZE\n","        X = np.clip(X,-1024,1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","            \n","        # BUTTER LOW-PASS FILTER\n","        X = self.butter_lowpass_filter(X)\n","        # Downsample\n","        X = X[::5,:]\n","        \n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","                \n","        return X,y\n","        \n","    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n","        nyquist = 0.5 * sampling_rate\n","        normal_cutoff = cutoff_freq / nyquist\n","        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","        filtered_data = lfilter(b, a, data, axis=0)\n","        return filtered_data\n","    \n","    def resize(self, img,size):\n","        composition = albu.Compose([\n","                albu.Resize(size[0],size[1])\n","            ])\n","        return composition(image=img)['image']\n","            \n","    def augmentation(self, img):\n","        composition = albu.Compose([\n","                albu.HorizontalFlip(p=0.4)\n","            ])\n","        return composition(image=img)['image']"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005596,"end_time":"2024-02-07T17:27:09.017756","exception":false,"start_time":"2024-02-07T17:27:09.01216","status":"completed"},"tags":[]},"source":["# DISPLAY DATA GENERATOR\n","Below we display example data generator spectrogram images and raw EEG signals."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.422622Z","iopub.status.busy":"2024-02-22T12:22:35.421979Z","iopub.status.idle":"2024-02-22T12:22:35.43236Z","shell.execute_reply":"2024-02-22T12:22:35.430772Z","shell.execute_reply.started":"2024-02-22T12:22:35.422587Z"},"papermill":{"duration":0.353959,"end_time":"2024-02-07T17:27:09.378243","exception":false,"start_time":"2024-02-07T17:27:09.024284","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if not submission and DATA_TYPE!='raw':\n","    gen = DataGenerator(train, augment=False, specs=spectrograms, eeg_specs=all_eegs, data_type=DATA_TYPE)\n","    for x,y in gen:\n","        break\n","    plt.imshow(x[:,:,0])\n","    plt.title(f'Target = {y.round(1)}',size=12)\n","    plt.yticks([])\n","    plt.ylabel('Frequencies (Hz)',size=12)\n","    plt.xlabel('Time (sec)',size=12)\n","    plt.show()\n","    \n","if not submission and DATA_TYPE=='raw':\n","    gen = DataGenerator(train, raw_eegs=all_raw_eegs, data_type=DATA_TYPE)\n","    for x,y in gen:\n","        plt.figure(figsize=(20,4))\n","        offset = 0\n","        for j in range(x.shape[-1]):\n","            if j!=0: offset -= x[:,j].min()\n","            plt.plot(range(2_000),x[:,j]+offset,label=f'feature {j+1}')\n","            offset += x[:,j].max()\n","        plt.legend()\n","        plt.show()\n","        break"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007604,"end_time":"2024-02-07T17:27:09.395313","exception":false,"start_time":"2024-02-07T17:27:09.387709","status":"completed"},"tags":[]},"source":["# TRAINING"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007689,"end_time":"2024-02-07T17:27:09.410982","exception":false,"start_time":"2024-02-07T17:27:09.403293","status":"completed"},"tags":[]},"source":["## LEARNING RATE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.434223Z","iopub.status.busy":"2024-02-22T12:22:35.43385Z","iopub.status.idle":"2024-02-22T12:22:35.45098Z","shell.execute_reply":"2024-02-22T12:22:35.44983Z","shell.execute_reply.started":"2024-02-22T12:22:35.434191Z"},"papermill":{"duration":0.203592,"end_time":"2024-02-07T17:27:09.62282","exception":false,"start_time":"2024-02-07T17:27:09.419228","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","if not submission:\n","\n","    def lrfn(epoch):\n","        e3 = 1e-3 if DATA_TYPE=='raw' else 1e-4\n","        return [1e-3,1e-3,e3,1e-4,1e-5][epoch]\n","\n","    LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n","    \n","    def lrfn2(epoch):\n","        return [1e-5,1e-5,1e-6][epoch]\n","\n","    LR2 = tf.keras.callbacks.LearningRateScheduler(lrfn2, verbose = True)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007926,"end_time":"2024-02-07T17:27:09.639381","exception":false,"start_time":"2024-02-07T17:27:09.631455","status":"completed"},"tags":[]},"source":["## MODEL AND UTILITY FUNCTIONS"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.453615Z","iopub.status.busy":"2024-02-22T12:22:35.452995Z","iopub.status.idle":"2024-02-22T12:22:35.476712Z","shell.execute_reply":"2024-02-22T12:22:35.47565Z","shell.execute_reply.started":"2024-02-22T12:22:35.45358Z"},"papermill":{"duration":0.023615,"end_time":"2024-02-07T17:27:09.671265","exception":false,"start_time":"2024-02-07T17:27:09.64765","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate\n","\n","def build_model():  \n","    inp = tf.keras.layers.Input((512,512,3))\n","    base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n","    x = base_model(inp)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    output = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n","    model = tf.keras.Model(inputs=inp, outputs=output)\n","    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n","    loss = tf.keras.losses.KLDivergence()\n","    model.compile(loss=loss, optimizer=opt)  \n","    return model\n","\n","def score(y_true, y_pred):\n","    kl = tf.keras.metrics.KLDivergence()\n","    return kl(y_true, y_pred)\n","\n","def wave_block(x, filters, kernel_size, n):\n","    dilation_rates = [2**i for i in range(n)]\n","    x = Conv1D(filters = filters,\n","               kernel_size = 1,\n","               padding = 'same')(x)\n","    res_x = x\n","    for dilation_rate in dilation_rates:\n","        tanh_out = Conv1D(filters = filters,\n","                          kernel_size = kernel_size,\n","                          padding = 'same', \n","                          activation = 'tanh', \n","                          dilation_rate = dilation_rate)(x)\n","        sigm_out = Conv1D(filters = filters,\n","                          kernel_size = kernel_size,\n","                          padding = 'same',\n","                          activation = 'sigmoid', \n","                          dilation_rate = dilation_rate)(x)\n","        x = Multiply()([tanh_out, sigm_out])\n","        x = Conv1D(filters = filters,\n","                   kernel_size = 1,\n","                   padding = 'same')(x)\n","        res_x = Add()([res_x, x])\n","    return res_x\n","\n","def build_wave_model():\n","        \n","    # INPUT \n","    inp = tf.keras.Input(shape=(2_000,8))\n","    \n","    ############\n","    # FEATURE EXTRACTION SUB MODEL\n","    inp2 = tf.keras.Input(shape=(2_000,1))\n","    x = wave_block(inp2, 8, 4, 6)\n","    x = wave_block(x, 16, 4, 6)\n","    x = wave_block(x, 32, 4, 6)\n","    x = wave_block(x, 64, 4, 6)\n","    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n","    ###########\n","    \n","    # LEFT TEMPORAL CHAIN\n","    x1 = model2(inp[:,:,0:1])\n","    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n","    x2 = model2(inp[:,:,1:2])\n","    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n","    z1 = tf.keras.layers.Average()([x1,x2])\n","    \n","    # LEFT PARASAGITTAL CHAIN\n","    x1 = model2(inp[:,:,2:3])\n","    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n","    x2 = model2(inp[:,:,3:4])\n","    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n","    z2 = tf.keras.layers.Average()([x1,x2])\n","    \n","    # RIGHT PARASAGITTAL CHAIN\n","    x1 = model2(inp[:,:,4:5])\n","    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n","    x2 = model2(inp[:,:,5:6])\n","    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n","    z3 = tf.keras.layers.Average()([x1,x2])\n","    \n","    # RIGHT TEMPORAL CHAIN\n","    x1 = model2(inp[:,:,6:7])\n","    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n","    x2 = model2(inp[:,:,7:8])\n","    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n","    z4 = tf.keras.layers.Average()([x1,x2])\n","    \n","    # COMBINE CHAINS\n","    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n","    y = tf.keras.layers.Dense(64, activation='relu')(y)\n","    y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n","    \n","    # COMPILE MODEL\n","    model = tf.keras.Model(inputs=inp, outputs=y)\n","    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n","    loss = tf.keras.losses.KLDivergence()\n","    model.compile(loss=loss, optimizer = opt)\n","    \n","    return model\n","\n","def plot_hist(hist):\n","    metrics = ['loss']\n","    for i,metric in enumerate(metrics):\n","        plt.figure(figsize=(10,4))\n","        plt.subplot(1,2,i+1)\n","        plt.plot(hist[metric])\n","        plt.plot(hist[f'val_{metric}'])\n","        plt.title(f'{metric}',size=12)\n","        plt.ylabel(f'{metric}',size=12)\n","        plt.xlabel('epoch',size=12)\n","        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008696,"end_time":"2024-02-07T17:27:09.688228","exception":false,"start_time":"2024-02-07T17:27:09.679532","status":"completed"},"tags":[]},"source":["## TRANSFER LEARNING"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.479089Z","iopub.status.busy":"2024-02-22T12:22:35.478637Z","iopub.status.idle":"2024-02-22T12:22:35.499005Z","shell.execute_reply":"2024-02-22T12:22:35.497877Z","shell.execute_reply.started":"2024-02-22T12:22:35.479037Z"},"papermill":{"duration":0.029503,"end_time":"2024-02-07T17:27:09.725805","exception":false,"start_time":"2024-02-07T17:27:09.696302","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.model_selection import KFold, GroupKFold\n","import tensorflow.keras.backend as K, gc\n","\n","if not submission:\n","    # for CV scores setting random seed works for single GPU only\n","    reset_seed(42)\n","    all_oof = []\n","    all_true = []\n","    losses = []\n","    val_losses = []\n","    total_hist = {}\n","\n","    gkf = GroupKFold(n_splits=5)\n","    for i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):   \n","        \n","        print('#'*25)\n","        print(f'### Fold {i+1}')\n","        \n","        data, val = train.iloc[train_index],train.iloc[valid_index]\n","        train_gen = DataGenerator(data, augment=False, specs=spectrograms, eeg_specs=all_eegs, raw_eegs=all_raw_eegs)\n","        valid_gen = DataGenerator(val, mode='valid', specs=spectrograms, eeg_specs=all_eegs, raw_eegs=all_raw_eegs)\n","        data, val = data[data['kl']<5.5],val[val['kl']<5.5]\n","        train_gen2 = DataGenerator(data, augment=False, specs=spectrograms, eeg_specs=all_eegs, raw_eegs=all_raw_eegs)\n","        in_shape = (2000,8) if DATA_TYPE=='raw' else (512,512,3)\n","        EPOCHS = 5 if DATA_TYPE=='raw' else 4\n","        BATCH_SIZE_PER_REPLICA = 8 if DATA_TYPE=='raw' else 32\n","        BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","\n","        train_dataset = tf.data.Dataset.from_generator(generator=train_gen, \n","                                                   output_signature=(tf.TensorSpec(shape=in_shape, dtype=tf.float32),\n","                                                                     tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","        val_dataset = tf.data.Dataset.from_generator(generator=valid_gen, \n","                                                   output_signature=(tf.TensorSpec(shape=in_shape, dtype=tf.float32),\n","                                                                     tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","        train_dataset2 = tf.data.Dataset.from_generator(generator=train_gen2, \n","                                                   output_signature=(tf.TensorSpec(shape=in_shape, dtype=tf.float32),\n","                                                                     tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","            \n","        print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n","        print('#'*25)\n","        \n","        K.clear_session()\n","        with strategy.scope():\n","            if DATA_TYPE=='raw':\n","                model = build_wave_model()\n","            else:\n","                model = build_model()\n","        \n","        hist = model.fit(train_dataset, validation_data = val_dataset, \n","                         epochs=EPOCHS, callbacks=[LR])\n","        print(f'### seconds stage train size {len(data)}, valid size {len(val)}')\n","        print('#'*25)\n","        hist2 = model.fit(train_dataset2, validation_data = val_dataset, \n","                         epochs=3, callbacks=[LR2])\n","        losses.append(hist.history['loss']+hist2.history['loss'])\n","        val_losses.append(hist.history['val_loss']+hist2.history['val_loss'])\n","        with strategy.scope():\n","            model.save_weights(f'model_{DATA_TYPE}_{VER}_{i}.weights.h5')\n","        oof = model.predict(val_dataset, verbose=1)\n","        all_oof.append(oof)\n","        all_true.append(train.iloc[valid_index][TARGETS].values)    \n","        del model, oof\n","        gc.collect()\n","        \n","    total_hist['loss'] = np.mean(losses,axis=0)\n","    total_hist['val_loss'] = np.mean(val_losses,axis=0)\n","    all_oof = np.concatenate(all_oof)\n","    all_true = np.concatenate(all_true)\n","    plot_hist(total_hist)\n","    print('#'*25)\n","    print(f'CV KL SCORE: {score(all_true,all_oof)}')"]},{"cell_type":"markdown","metadata":{},"source":["# Infer Test and Create Submission CSV\n","Infer the test data and create a `submission.csv` file."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-02-22T12:22:35.503455Z","iopub.status.busy":"2024-02-22T12:22:35.502958Z","iopub.status.idle":"2024-02-22T12:22:35.528921Z","shell.execute_reply":"2024-02-22T12:22:35.527886Z","shell.execute_reply.started":"2024-02-22T12:22:35.503411Z"},"papermill":{"duration":0.034306,"end_time":"2024-02-07T17:27:09.784426","exception":false,"start_time":"2024-02-07T17:27:09.75012","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pywt, librosa\n","\n","USE_WAVELET = None \n","\n","NAMES = ['LL','LP','RP','RR']\n","\n","FEATS = [['Fp1','F7','T3','T5','O1'],\n","         ['Fp1','F3','C3','P3','O1'],\n","         ['Fp2','F8','T4','T6','O2'],\n","         ['Fp2','F4','C4','P4','O2']]\n","\n","# DENOISE FUNCTION\n","def maddest(d, axis=None):\n","    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n","\n","def denoise(x, wavelet='haar', level=1):    \n","    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n","    sigma = (1/0.6745) * maddest(coeff[-level])\n","\n","    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n","    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n","\n","    ret=pywt.waverec(coeff, wavelet, mode='per')\n","    \n","    return ret\n","\n","import librosa\n","\n","def spectrogram_from_eeg(parquet_path, display=False):\n","    \n","    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n","    eeg = pd.read_parquet(parquet_path)\n","    middle = (len(eeg)-10_000)//2\n","    eeg = eeg.iloc[middle:middle+10_000]\n","    \n","    # VARIABLE TO HOLD SPECTROGRAM\n","    img = np.zeros((100,300,4),dtype='float32')\n","    \n","    if display: plt.figure(figsize=(10,7))\n","    signals = []\n","    for k in range(4):\n","        COLS = FEATS[k]\n","        \n","        for kk in range(4):\n","            # FILL NANS\n","            x1 = eeg[COLS[kk]].values\n","            x2 = eeg[COLS[kk+1]].values\n","            m = np.nanmean(x1)\n","            if np.isnan(x1).mean()<1: x1 = np.nan_to_num(x1,nan=m)\n","            else: x1[:] = 0\n","            m = np.nanmean(x2)\n","            if np.isnan(x2).mean()<1: x2 = np.nan_to_num(x2,nan=m)\n","            else: x2[:] = 0\n","                \n","            # COMPUTE PAIR DIFFERENCES\n","            x = x1 - x2\n","\n","            # DENOISE\n","            if USE_WAVELET:\n","                x = denoise(x, wavelet=USE_WAVELET)\n","            signals.append(x)\n","\n","            # RAW SPECTROGRAM\n","            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n","                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n","            \n","            # LOG TRANSFORM\n","            width = (mel_spec.shape[1]//30)*30\n","            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n","            img[:,:,k] += mel_spec_db\n","                \n","        # AVERAGE THE 4 MONTAGE DIFFERENCES\n","        img[:,:,k] /= 4.0\n","        \n","        if display:\n","            plt.subplot(2,2,k+1)\n","            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n","            \n","    if display: \n","        plt.show()\n","        plt.figure(figsize=(10,5))\n","        offset = 0\n","        for k in range(4):\n","            if k>0: offset -= signals[3-k].min()\n","            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n","            offset += signals[3-k].max()\n","        plt.legend()\n","        plt.show()\n","        \n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.533164Z","iopub.status.busy":"2024-02-22T12:22:35.532109Z","iopub.status.idle":"2024-02-22T12:22:35.549093Z","shell.execute_reply":"2024-02-22T12:22:35.547961Z","shell.execute_reply.started":"2024-02-22T12:22:35.533131Z"},"papermill":{"duration":0.029223,"end_time":"2024-02-07T17:27:09.821959","exception":false,"start_time":"2024-02-07T17:27:09.792736","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if submission:\n","    test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n","    print('Test shape',test.shape)\n","    test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.550703Z","iopub.status.busy":"2024-02-22T12:22:35.550341Z","iopub.status.idle":"2024-02-22T12:22:35.776779Z","shell.execute_reply":"2024-02-22T12:22:35.77565Z","shell.execute_reply.started":"2024-02-22T12:22:35.550671Z"},"papermill":{"duration":0.239453,"end_time":"2024-02-07T17:27:10.070021","exception":false,"start_time":"2024-02-07T17:27:09.830568","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# READ ALL SPECTROGRAMS\n","if submission:\n","    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\n","    files2 = os.listdir(PATH2)\n","    print(f'There are {len(files2)} test spectrogram parquets')\n","    \n","    spectrograms2 = {}\n","    for i,f in enumerate(files2):\n","        if i%100==0: print(i,', ',end='')\n","        tmp = pd.read_parquet(f'{PATH2}{f}')\n","        name = int(f.split('.')[0])\n","        spectrograms2[name] = tmp.iloc[:,1:].values\n","    \n","    # RENAME FOR DATA GENERATOR\n","    test = test.rename({'spectrogram_id':'spec_id'},axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:35.778598Z","iopub.status.busy":"2024-02-22T12:22:35.777931Z","iopub.status.idle":"2024-02-22T12:22:48.898554Z","shell.execute_reply":"2024-02-22T12:22:48.897187Z","shell.execute_reply.started":"2024-02-22T12:22:35.778556Z"},"papermill":{"duration":11.019,"end_time":"2024-02-07T17:27:21.097614","exception":false,"start_time":"2024-02-07T17:27:10.078614","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# READ ALL EEG SPECTROGRAMS\n","if submission:\n","    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n","    DISPLAY = 0\n","    EEG_IDS2 = test.eeg_id.unique()\n","    all_eegs2 = {}\n","\n","    print('Converting Test EEG to Spectrograms...'); print()\n","    for i,eeg_id in enumerate(EEG_IDS2):\n","        \n","        # CREATE SPECTROGRAM FROM EEG PARQUET\n","        img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n","        all_eegs2[eeg_id] = img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:48.902449Z","iopub.status.busy":"2024-02-22T12:22:48.900539Z","iopub.status.idle":"2024-02-22T12:22:48.933562Z","shell.execute_reply":"2024-02-22T12:22:48.932237Z","shell.execute_reply.started":"2024-02-22T12:22:48.90239Z"},"trusted":true},"outputs":[],"source":["# READ ALL RAW EEG SIGNALS\n","if submission :\n","    all_raw_eegs2 = {}\n","    EEG_IDS2 = test.eeg_id.unique()\n","    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n","\n","    print('Processing Test EEG parquets...'); print()\n","    for i,eeg_id in enumerate(EEG_IDS2):\n","        \n","        # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n","        data = eeg_from_parquet(f'{PATH2}{eeg_id}.parquet')\n","        all_raw_eegs2[eeg_id] = data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:48.936612Z","iopub.status.busy":"2024-02-22T12:22:48.935685Z","iopub.status.idle":"2024-02-22T12:22:48.949188Z","shell.execute_reply":"2024-02-22T12:22:48.947858Z","shell.execute_reply.started":"2024-02-22T12:22:48.936561Z"},"papermill":{"duration":20.951008,"end_time":"2024-02-07T17:27:42.060528","exception":false,"start_time":"2024-02-07T17:27:21.10952","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Submission ON TEST without ensemble\n","if submission and not ENSEMBLE:\n","    preds = []\n","    \n","    if DATA_TYPE=='raw':\n","        test_gen = DataGenerator(test, mode='test', raw_eegs=all_raw_eegs2)\n","        in_shape = (2000,8)\n","    else:\n","        test_gen = DataGenerator(test, mode='test', specs = spectrograms2, eeg_specs = all_eegs2)\n","        in_shape = (512,512,3)\n","    \n","    test_dataset = tf.data.Dataset.from_generator(generator=test_gen, \n","                                               output_signature=(tf.TensorSpec(shape=in_shape, dtype=tf.float32),\n","                                                                 tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(64).prefetch(tf.data.AUTOTUNE)\n","    if DATA_TYPE=='raw':\n","        model = build_wave_model()\n","    else:\n","        model = build_model()\n","\n","    for i in range(5):\n","        print(f'Fold {i+1}')\n","        model.load_weights(f'{LOAD_MODELS_FROM}model_{DATA_TYPE}_{VER}_{i}.weights.h5')\n","        pred = model.predict(test_dataset, verbose=1)\n","        preds.append(pred)\n","        \n","    pred = np.mean(preds,axis=0)\n","    print('Test preds shape',pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:22:48.952284Z","iopub.status.busy":"2024-02-22T12:22:48.951311Z","iopub.status.idle":"2024-02-22T12:23:59.320341Z","shell.execute_reply":"2024-02-22T12:23:59.319231Z","shell.execute_reply.started":"2024-02-22T12:22:48.95222Z"},"trusted":true},"outputs":[],"source":["# Submission ON TEST with ensemble\n","if submission and ENSEMBLE:\n","    preds = []\n","    test_gen_kaggle = DataGenerator(test, mode='test', data_type='kaggle', specs = spectrograms2, eeg_specs = all_eegs2)\n","    test_dataset_kaggle = tf.data.Dataset.from_generator(generator=test_gen_kaggle, \n","                                               output_signature=(tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),\n","                                                                 tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(64).prefetch(tf.data.AUTOTUNE)\n","    test_gen_both = DataGenerator(test, mode='test', data_type='both', specs = spectrograms2, eeg_specs = all_eegs2)\n","    test_dataset_both = tf.data.Dataset.from_generator(generator=test_gen_both, \n","                                               output_signature=(tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),\n","                                                                 tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(64).prefetch(tf.data.AUTOTUNE)\n","\n","    test_gen_eeg = DataGenerator(test, mode='test', data_type='eeg', specs = spectrograms2, eeg_specs = all_eegs2)\n","    test_dataset_eeg = tf.data.Dataset.from_generator(generator=test_gen_eeg, \n","                                               output_signature=(tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),\n","                                                                 tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(64).prefetch(tf.data.AUTOTUNE)\n","    test_gen_raw = DataGenerator(test, mode='test', data_type='raw', raw_eegs=all_raw_eegs2)\n","    test_dataset_raw = tf.data.Dataset.from_generator(generator=test_gen_raw, \n","                                               output_signature=(tf.TensorSpec(shape=(2000,8), dtype=tf.float32),\n","                                                                 tf.TensorSpec(shape=(6,), dtype=tf.float32))).batch(64).prefetch(tf.data.AUTOTUNE)\n"," \n","    # LB SCORE FOR EACH MODEL\n","    lbs = 1 - np.array(LBs)\n","    weights = lbs/lbs.sum()\n","    model = build_model()\n","    model_wave = build_wave_model()\n","\n","    for i in range(5):\n","        print(f'Fold {i+1}')\n","        \n","        model.load_weights(f'{LOAD_MODELS_FROM}model_kaggle_{VERK}_{i}.weights.h5')\n","        pred_kaggle = model.predict(test_dataset_kaggle, verbose=1)\n","        \n","        model.load_weights(f'{LOAD_MODELS_FROM}model_both_{VERB}_{i}.weights.h5')\n","        pred_both = model.predict(test_dataset_both, verbose=1)\n","        \n","        model.load_weights(f'{LOAD_MODELS_FROM}model_eeg_{VERE}_{i}.weights.h5')\n","        pred_eeg = model.predict(test_dataset_eeg, verbose=1)\n","        \n","        model_wave.load_weights(f'{LOAD_MODELS_FROM}model_raw_{VERR}_{i}.weights.h5')\n","        pred_raw = model_wave.predict(test_dataset_raw, verbose=1)\n","        \n","        pred = np.array([pred_both,pred_eeg,pred_kaggle,pred_raw])\n","        pred = np.average(pred,axis=0,weights=weights)\n","        preds.append(pred)\n","        \n","    pred = np.mean(preds,axis=0)\n","    print('Test preds shape',pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:23:59.322584Z","iopub.status.busy":"2024-02-22T12:23:59.322206Z","iopub.status.idle":"2024-02-22T12:23:59.341399Z","shell.execute_reply":"2024-02-22T12:23:59.340539Z","shell.execute_reply.started":"2024-02-22T12:23:59.322551Z"},"papermill":{"duration":0.03493,"end_time":"2024-02-07T17:27:42.105112","exception":false,"start_time":"2024-02-07T17:27:42.070182","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if submission:\n","    sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n","    sub[TARGETS] = pred\n","    sub.to_csv('submission.csv',index=False)\n","    print('Submissionn shape',sub.shape)\n","    print()\n","    print(sub.head().to_string())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T12:23:59.34341Z","iopub.status.busy":"2024-02-22T12:23:59.342816Z","iopub.status.idle":"2024-02-22T12:23:59.353313Z","shell.execute_reply":"2024-02-22T12:23:59.352101Z","shell.execute_reply.started":"2024-02-22T12:23:59.343356Z"},"papermill":{"duration":0.023201,"end_time":"2024-02-07T17:27:42.139259","exception":false,"start_time":"2024-02-07T17:27:42.116058","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n","if submission:\n","    print(sub.iloc[:,-6:].sum(axis=1).to_string())"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297782,"sourceId":7392775,"sourceType":"datasetVersion"},{"datasetId":4317718,"sourceId":7465251,"sourceType":"datasetVersion"},{"datasetId":4407194,"sourceId":7570342,"sourceType":"datasetVersion"},{"datasetId":4382744,"sourceId":7626715,"sourceType":"datasetVersion"},{"datasetId":4417235,"sourceId":7678210,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":279.932947,"end_time":"2024-02-07T17:27:46.449789","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-07T17:23:06.516842","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
